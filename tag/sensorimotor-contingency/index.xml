<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sensorimotor contingency | Richard Schweitzer</title>
    <link>https://richardschweitzer.github.io/tag/sensorimotor-contingency/</link>
      <atom:link href="https://richardschweitzer.github.io/tag/sensorimotor-contingency/index.xml" rel="self" type="application/rss+xml" />
    <description>sensorimotor contingency</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 26 Jul 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://richardschweitzer.github.io/media/icon_hubfee2d95eacbb9353231e71bd25fb589_9055_512x512_fill_lanczos_center_3.png</url>
      <title>sensorimotor contingency</title>
      <link>https://richardschweitzer.github.io/tag/sensorimotor-contingency/</link>
    </image>
    
    <item>
      <title>High-fidelity but hypometric spatial localization of afterimages across saccades</title>
      <link>https://richardschweitzer.github.io/publication/schweitzerseelraischrolfs_ai_2025/</link>
      <pubDate>Sat, 26 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://richardschweitzer.github.io/publication/schweitzerseelraischrolfs_ai_2025/</guid>
      <description>&lt;p&gt;In low-light environments, brief high-intensity visual stimulation can induce long-lasting retinal afterimages. When observers then make eye movements to explore their visual environment, these afterimages – albeit fixed in the retinotopic frame of reference – appear to move in egocentric space wherever the eye moves. Even though this phenomenon has been known for centuries, the underlying computations remained unexplained. Tracking eye and afterimage positions simultaneously, we found that perceived afterimage position was accurately predicted by eye position across a variety of visuomotor conditions, whereby the eye movement’s size was however systematically underestimated by the visual system. Considering a parsimonious model of visual localization, afterimage movement can be understood as a consequence of feedforward predictions of the visual consequences of impending eye movements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Early visual signatures and benefits of intra-saccadic motion streaks</title>
      <link>https://richardschweitzer.github.io/publication/schweitzerseelraischrolfs_eeg_2025/</link>
      <pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://richardschweitzer.github.io/publication/schweitzerseelraischrolfs_eeg_2025/</guid>
      <description>&lt;p&gt;To efficiently explore our visual environment, we humans incessantly make brief and rapid eye movements. These so-called saccades inevitably shift the entire visual image across the retina, thereby inducing - like a moving camera with long exposure duration - a significant amount of motion blur, transforming single objects into elongated smeared motion streaks. While simultaneously recording electroencephalography and eye tracking, we asked human observers to make saccades to a target stimulus which then rapidly changed location while their eyes were in mid-flight. Critically, we compared smooth target motion to a simple jump, thus isolating neural responses and behavioral benefits specific to motion streaks: For continuous motion (i.e., when streaks were available), the post-saccadic target location could be decoded earlier from electrophysiological data and secondary saccades went more quickly to the new target location. Indeed, decoding of target location succeeded immediately after the end of the saccade and was most efficient on occipital sensors, suggesting that saccade-induced motion streaks are represented in visual cortex. &lt;a href=&#34;https://github.com/richardschweitzer/simplified_V1&#34; target=&#34;_blank&#34;&gt;Computational modeling&lt;/a&gt; of saccades as a consequence of early visual processes suggests that fast motion could be efficiently coded in orientation-selective channels, providing a parsimonious mechanism by which the brain exploits motion streaks for goal-directed behavior.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lawful kinematics link eye movements to the limits of high-speed perception</title>
      <link>https://richardschweitzer.github.io/publication/rolfsschweitzercastetwatsonohl2023/</link>
      <pubDate>Thu, 08 May 2025 00:00:00 +0000</pubDate>
      <guid>https://richardschweitzer.github.io/publication/rolfsschweitzercastetwatsonohl2023/</guid>
      <description>&lt;p&gt;In this paper, we report a mysterious finding. When detecting rapid stimulus motion of a Gabor stimulus oriented orthogonal to its motion direction, it is not simply its absolute velocity that determines its visibility, but a combination of velocity and movement distance. Curiously, the specific combination that predicts velocity thresholds follows an oculomotor law - the main sequence, an exponential function describing the increase of saccadic velocity with growing amplitude. My proud contributions to this paper feature the &lt;a href=&#34;https://osf.io/kvtsu/&#34; target=&#34;_blank&#34;&gt;masking experiment&lt;/a&gt;, the &lt;a href=&#34;https://github.com/richardschweitzer/PostsaccadicOscillations&#34; target=&#34;_blank&#34;&gt;modeling of saccade trajectories&lt;/a&gt; which ultimately revealed significant correlations between saccade metrics and velocity thresholds, and most importantly, the &lt;a href=&#34;https://github.com/richardschweitzer/ModelingVisibilityOfSaccadelikeMotion&#34; target=&#34;_blank&#34;&gt;early vision model&lt;/a&gt; to predict the measured psychophysical data - without fitting and based only on the trajectory of the stimulus. Finally, I evaluated the timing of the motion stimulus using photometric measurements using the &lt;a href=&#34;https://github.com/richardschweitzer/LM03_lightmeter&#34; target=&#34;_blank&#34;&gt;LM03 lightmeter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Coupling perception to action through incidental sensory consequences of motor behaviour</title>
      <link>https://richardschweitzer.github.io/publication/rolfsschweitzer2022/</link>
      <pubDate>Wed, 02 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://richardschweitzer.github.io/publication/rolfsschweitzer2022/</guid>
      <description>&lt;p&gt;This perspective paper is dedicated to the question how an active perceptual system deals with the sensory consequences of its own actions. For instance, in the field of active vision little is known about the consequences of large-field smear induced by the rapid image shift caused by saccades. Whereas such information is thought to hinder visual processing, new evidence is discussed that sheds light on the intriguing possibility of action-perception couplings, that is, the idea that perception is shaped by sensory consequences of actions.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
