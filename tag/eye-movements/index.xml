<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>eye movements | Richard Schweitzer</title>
    <link>https://richardschweitzer.github.io/tag/eye-movements/</link>
      <atom:link href="https://richardschweitzer.github.io/tag/eye-movements/index.xml" rel="self" type="application/rss+xml" />
    <description>eye movements</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 28 Feb 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://richardschweitzer.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>eye movements</title>
      <link>https://richardschweitzer.github.io/tag/eye-movements/</link>
    </image>
    
    <item>
      <title>Definition, Modeling, and Detection of Saccades in the Face of Post-saccadic Oscillations</title>
      <link>https://richardschweitzer.github.io/publication/schweitzerrolfs2022_eyetracking/</link>
      <pubDate>Mon, 28 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://richardschweitzer.github.io/publication/schweitzerrolfs2022_eyetracking/</guid>
      <description>&lt;p&gt;When looking at data recorded by video-based eye tracking systems, one might have noticed brief periods of instability around saccade offset. These so-called post-saccadic oscillations are caused by inertial forces that act on the elastic components of the eye, such as the iris or the lens, and can greatly distort estimates of saccade duration and peak velocity. In this paper, we describe and evaluate biophysically plausible models (for a demonstration, see the &lt;a href=&#34;https://richardschweitzer.shinyapps.io/pso_fitting_example/&#34; target=&#34;_blank&#34;&gt;shiny app&lt;/a&gt;) that can not only approximate saccade trajectories observed in video-based eye tracking, but also extract the underlying &amp;ndash; and otherwise unobservable &amp;ndash; rotation of the eyeball. We further present detection algorithms for post-saccadic oscillations, which are made &lt;a href=&#34;https://github.com/richardschweitzer/PostsaccadicOscillations&#34; target=&#34;_blank&#34;&gt;publicly available&lt;/a&gt;, and finally demonstrate how accurate models of saccade trajectory can be used to generate data and mathematically tractable ground-truth labels for training ML-based algorithms that are capable of accurately detecting post-saccadic oscillations.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Coupling perception to action through incidental sensory consequences of motor behaviour</title>
      <link>https://richardschweitzer.github.io/publication/rolfsschweitzer2022/</link>
      <pubDate>Wed, 02 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://richardschweitzer.github.io/publication/rolfsschweitzer2022/</guid>
      <description>&lt;p&gt;This perspective paper is dedicated to the question how an active perceptual system deals with the sensory consequences of its own actions. For instance, in the field of active vision little is known about the consequences of large-field smear induced by the rapid image shift caused by saccades. Whereas such information is thought to hinder visual processing, new evidence is discussed that sheds light on the intriguing possibility of action-perception couplings, that is, the idea that perception is shaped by sensory consequences of actions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intrasaccadic motion streaks jump-start gaze correction</title>
      <link>https://richardschweitzer.github.io/publication/schweitzerrolfs2021_sciadv/</link>
      <pubDate>Fri, 23 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://richardschweitzer.github.io/publication/schweitzerrolfs2021_sciadv/</guid>
      <description>&lt;p&gt;In this piece we showed that the visual traces that moving objects induce during saccades can facilitate secondary saccades in both accuracy and saccade initiation latency. Secondary saccades are typically prompted when one saccade does not entirely reach a target or when the saccade target is displaced in mid-flight. Our results provide evidence against the widely acknowledged notion that our brains preemptively discard visual information which reaches the eye during saccades. The paper has received some peer and media attention, such as a well-written &lt;a href=&#34;https://www.science.org/doi/10.1126/sciadv.abk0043&#34; target=&#34;_blank&#34;&gt;commentary by Jasper Fabius and Stefan van der Stigchel&lt;/a&gt;, as well as articles in &lt;a href=&#34;https://www.nature.com/articles/d41586-021-02058-9&#34; target=&#34;_blank&#34;&gt;Nature Research Highlights&lt;/a&gt;, &lt;a href=&#34;https://www.aaas.org/news/human-eyes-absorb-visual-information-even-during-rapid-eye-movements&#34; target=&#34;_blank&#34;&gt;AAAS&lt;/a&gt;, &lt;a href=&#34;https://www.newscientist.com/article/2285131-we-thought-our-eyes-turned-off-when-moving-quickly-but-thats-wrong/&#34; target=&#34;_blank&#34;&gt;New Scientist&lt;/a&gt;, or &lt;a href=&#34;https://www.vozpopuli.com/next/ojos-movimientos-sacadicos.html&#34; target=&#34;_blank&#34;&gt;Vozp√≥puli&lt;/a&gt; (see &lt;a href=&#34;https://rolfslab.org/2021/08/09/press-coverage-on-science-advances-paper/&#34; target=&#34;_blank&#34;&gt;the Rolfslab&#39;s blog post&lt;/a&gt; for the full list). Notably, this study is the first one to apply the new TrackPixx eye tracking system, for which I have written a &lt;a href=&#34;https://github.com/richardschweitzer/TrackPixxToolbox&#34; target=&#34;_blank&#34;&gt;Matlab toolbox&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intra-saccadic motion streaks as cues to linking object locations across saccades</title>
      <link>https://richardschweitzer.github.io/publication/schweitzerrolfs2020_jov/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://richardschweitzer.github.io/publication/schweitzerrolfs2020_jov/</guid>
      <description>&lt;p&gt;Whenever we make a saccade to an object, that object will travel from the periphery to the fovea at extremely high velocities. Depending on the visual features of the object, such motion can induce streaks, that may serve as visual clues to solve the problem of trans-saccadic object correspondence. Using a high-speed projection system operating at 1440 fps, we investigated to what extent human observers are capable of matching pre- and post-saccadic object locations when their only cue was an intra-saccadic motion streak, and compared their performance during saccades to a replay of the retinal stimulus trajectory presented during fixation.&lt;/p&gt;
&lt;p&gt;A toolbox for parsing Eyelink EDF files was implemented in R to analyze this series of experiments, which can be found &lt;a href=&#34;https://github.com/richardschweitzer/EyelinkEDFTools_R&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An adaptive algorithm for fast and reliable online saccade detection</title>
      <link>https://richardschweitzer.github.io/publication/schweitzerrolfs2020_brm/</link>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://richardschweitzer.github.io/publication/schweitzerrolfs2020_brm/</guid>
      <description>&lt;p&gt;To study intrasaccadic vision, we need stimulus manipulations that occur strictly during saccades. Due to the brief durations of saccades, this can prove a difficult task, as various system latencies (eye tracker, refresh cycle, video delay, and some more) have to be considered. While most of these delays are hardware-dependent, one opportunity to alleviate timing issues in gaze-contingent eye-tracking paradigms is applying an efficient online saccade detection! In this paper we described such an algorithm, validated it in simulations and experiments, and made it &lt;a href=&#34;https://github.com/richardschweitzer/OnlineSaccadeDetection&#34; target=&#34;_blank&#34;&gt;publicly available&lt;/a&gt;) so that it can be used with a range of different programming languages.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Joy of Retinal Painting: A Build-It-Yourself Device for Intrasaccadic Presentations</title>
      <link>https://richardschweitzer.github.io/publication/schweitzerwatsonwatsonrolfs2019/</link>
      <pubDate>Sat, 03 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://richardschweitzer.github.io/publication/schweitzerwatsonwatsonrolfs2019/</guid>
      <description>&lt;p&gt;Everyone knows this nice party trick: Try to observe your own rapid eye movements (so-called saccades) in the mirror &amp;ndash; and realize that you will not be able to. Despite this striking example, we are not blind during saccades. This paper features a demonstration (as well as schematics and code to built it yourself) that is capable of producing highly salient, nicely resolvable stimuli which can only be perceived during saccades!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>All is not lost: Post-saccadic contributions to the perceptual omission of intra-saccadic streaks</title>
      <link>https://richardschweitzer.github.io/publication/balsdonschweitzerwatsonrolfs2018/</link>
      <pubDate>Sat, 19 May 2018 00:00:00 +0000</pubDate>
      <guid>https://richardschweitzer.github.io/publication/balsdonschweitzerwatsonrolfs2018/</guid>
      <description>&lt;p&gt;When objects rapidly shift across the retina during saccades, they produce so-called motion streaks &amp;ndash; elongated traces of the stimulus trajectory. During natural vision, however, we rarely notice this type of smearing. Previous studies have shown that the mere presence of stimulus after the saccade can achieve this &amp;lsquo;saccadic omission&amp;rsquo;. Tarryn&amp;rsquo;s study investigates not only the time course of this process but also the unexpected role of distractor stimuli. She has written a nice piece on her work for &lt;a href=&#34;https://sciencetrends.com/gaps-in-perception-how-we-see-a-stable-world-through-moving-eyes/&#34; target=&#34;_blank&#34;&gt;Science Trends&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
